<!DOCTYPE HTML>
<html lang="en">
  <head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->

  <title>Shaunak Halbe</title>
  <!-- hello -->
  <meta name="author" content="Shaunak Halbe">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv='cache-control' content='no-cache'> 
  <meta http-equiv='expires' content='0'> 
  <meta http-equiv='pragma' content='no-cache'>

  <link rel="stylesheet" type="text/css" href="./stylesheet.css">
  <link rel="icon" type="image/png" href="data/GTVertical_RGB.png">
</head>
<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:60%;vertical-align:top">
                  <p style="text-align:left;margin:0">
                    <name>Shaunak Halbe</name>
                  <p></p>
                  ML PhD student
                  <br>
                  <a href="https://gatech.edu" target="_blank">Georgia Institute of Technology</a>

                  <p>
                    <br>
                  <a href="mailto:shalbe9@gatech.edu">Email</a> &nbsp/&nbsp
                <a href="data/ShaunakCVM.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Biography</a> &nbsp/&nbsp -->
                <a href="https://www.linkedin.com/in/shaunak-halbe-565a0716b/">LinkedIn</a> &nbsp/&nbsp
                <!-- <a href="https://github.com/shaunak27">Github</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=7-VApYcAAAAJ&hl=en">Google Scholar</a> 
                 </p>
                  <img style="width: 40%;padding: 10px 0px;" src="./data/GTVertical_RGB.png">
                  </p>
                <td style="padding:2.5%;width:40%;max-width:40%">
                      <a href="#"><img style="width:90%;border-radius: 0%" alt="profile photo" src="data/WhatsApp Image 2023-06-22 at 11.56.29 PM.jpeg" class="hoverZoomLink"></a>
                </td>
              </tr>
          </tr>
          <tr>
            <td colspan="2" style="
            border-top: 1px solid black;
            border-bottom: 1px solid black;">
              <div class="topbar" style="text-align:center">

                <a href="#about">About</a> &nbsp|&nbsp
                <a href="#research">Research</a>&nbsp|&nbsp
                <a href="#awards">Awards</a>&nbsp|&nbsp
                <a href="#service">Service</a>&nbsp&nbsp
              </div>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading id="about">About</heading>
              <p>
                I am a second year Machine Learning PhD student at Georgia Tech advised by Prof. <a href="https://faculty.cc.gatech.edu/~zk15/">Zsolt Kira</a>. My research interests lie at the intersection of computer vision and natural language processing.
                <br><br> I am currently working on vision-and-language pretraining, (egocentric) video understanding and domain adaptation.  <br><br> At Georgia Tech, I have been working on building vision-and-language models capable of understanding the open-world. Previously, I have worked on domain generalization and robustness at USC/Meta AI and on embodied visual navigation at CMU.</p>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading id="research">Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
         
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              
              <div class="one">
                <!-- <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nlt_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='data/method.png' style = "width:100%; height:100%">
              </div>
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://www.aclweb.org/anthology/2020.challengehml-1.9/"> -->
                <papertitle>Grounding Descriptions in Images informs Zero-shot Visual Recognition</papertitle>
              <!-- </a> -->
              <br><br>
              <strong>Shaunak Halbe</strong><sup>*</sup> et. al.
              <br> 
              <br>
              <em>Under Review</em>  
              <br>
             
              <!-- <a href="http://nlt.csail.mit.edu/">project page</a> / -->
              
              <a href="data/GRAIN_full.pdf">preprint</a>
              <p>We propose a new pretraining strategy for CLIP to learn fine-grained visual representations that exhibit strong zero-shot transfer performance.</p>
            </td>
          </tr>
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              
              <div class="one">
                <!-- <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nlt_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='data/teaser.png' style = "width:100%; height:100%">
              </div>
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://www.aclweb.org/anthology/2020.challengehml-1.9/"> -->
                <papertitle>Continual Adaptation of Foundation Models for Federated Learning</papertitle>
              <!-- </a> -->
              <br><br>
              <strong>Shaunak Halbe</strong><sup>*</sup>, James  Smith, Junjiao Tian, Zsolt Kira
              <br> 
              <br>
              <em>Workshop on Federated Learning in the Age of Foundation Models</em> <b>(Oral)</b>  
              <br>
              <strong>NeurIPS 2023</strong> <br>
              Long Version: Under Submission <br>
              <!-- <a href="http://nlt.csail.mit.edu/">project page</a> / -->
              
              <a href="https://arxiv.org/pdf/2306.09970.pdf">paper</a> / 
              <a href="https://neurips.cc/virtual/2023/79009">talk</a>
              <p>We propose a novel prompt learning and aggregation scheme for distributed training of foundation models</p>
            </td>
          </tr>
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              
              <div class="one">
                <!-- <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nlt_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='data/corl.png' style = "width:100%; height:100%">
              </div>
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://www.aclweb.org/anthology/2020.challengehml-1.9/"> -->
                <papertitle>Open-World Dialogue Driven Object Navigation</papertitle>
              <!-- </a> -->
              <br><br>
              <strong>Conference on Robot Learning (CoRL) 2023 (Demo Track)</strong>  
              <br>
              <!-- <a href="http://nlt.csail.mit.edu/">project page</a> / -->
              
              <a href="#">Coming Soon</a>
              <p>We demonstrate robot navigation to an open-set of objects described in natural language</p>
            </td>
          </tr>
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              
              <div class="one">
                <!-- <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nlt_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='data/toy_example.svg' style = "width:100%; height:100%">
              </div>
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://www.aclweb.org/anthology/2020.challengehml-1.9/"> -->
                <papertitle>Robustness through Data Augmentation Loss Consistency</papertitle>
              <!-- </a> -->
              <br><br>
              Tianjian Huang<sup>*</sup>, <strong>Shaunak Halbe</strong><sup>*</sup>, Chinnadhurai Sankar, Pooyan Amini, Satwik Kottur, Alborz Geramifard, Meisam Razaviyayn, Ahmad Beirami
              <br>
              <br>
              <strong>Transactions on Machine Learning Research (TMLR) 2022</strong>  
              <br>
              <!-- <a href="http://nlt.csail.mit.edu/">project page</a> / -->
              
              <a href="https://arxiv.org/pdf/2110.11205.pdf">paper</a>
              <p>We introduce a novel loss-level regularizer to improve robustness to spurious correlations in generative models</p>
            </td>
          </tr>
          
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              
              <div class="one">
                <!-- <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nlt_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='data/clvision.png' style = "width:100%; height:100%">
              </div>
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://www.aclweb.org/anthology/2020.challengehml-1.9/"> -->
                <papertitle>A Closer Look at Rehearsal-Free Continual Learning</papertitle>
              <!-- </a> -->
              <br><br>
              James  Smith, Junjiao Tian, <strong>Shaunak Halbe</strong>, Yen-Chang Hsu, Zsolt Kira
              <br><br>
              <em>Workshop on Continual Learning in Computer Vision (CLVision)</em>  
              <br>
      
              <strong>CVPR 2023</strong>
              
              <br>
              <!-- <a href="http://nlt.csail.mit.edu/">project page</a> / -->
              
              <a href="https://arxiv.org/pdf/2203.17269.pdf">paper</a>
              <p>We introduce knowledge distillation and regularization baselines using Foundation Models for rehearsal-free continual learning</p>
            </td>
          </tr>


          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              
              <div class="one">
                <!-- <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nlt_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='data/KG_final.png' style = "width:100%; height:100%">
              </div>
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://www.aclweb.org/anthology/2020.challengehml-1.9/"> -->
                <papertitle>Reason & Act : A Modular Approach to Explanation Driven Agents for Vision and Language Navigation</papertitle>
              <!-- </a> -->
              <br><br>
               <strong>Shaunak Halbe</strong>, Ingrid Navarro, Jean Oh
              <br>
              <em>CMU Robotics Institute of Summer Scholars Working Papers Journal</em>  
              <br>
              <!-- <a href="http://nlt.csail.mit.edu/">project page</a> / -->
              <a href="data/riss_paper.pdf">paper</a> /
              <a href="https://drive.google.com/file/d/1JdU1e3EpVPRZD6yjz5s5TeW5MTXyt-HU/view?usp=sharing">poster</a> /
              <a href="https://youtu.be/AazE5aZHgc0">talk</a>
              <p></p>
              <p>We present a modular agent for navigation with improved cross-modal grounding and semantic reasoning.</p>
            </td>
          </tr>

          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              
              <div class="one">
                <!-- <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nlt_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='data/mygif.gif' style = "width:100%; height:100%">
              </div>
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Exploring Weaknesses of VQA Models through Attribution Driven Insights</papertitle>
              <br><br>
          
              <strong>Shaunak Halbe</strong>
              
              <br>
              <em>Second Grand-Challenge and Workshop on Multimodal Language</em>  
              <br>
      
              <strong>ACL 2020</strong>
               <br>
               <em>Visual Question Answering and Dialog Workshop</em>
               <br>
               <strong>CVPR 2020</strong>
              <br>
              <!-- <a href="http://nlt.csail.mit.edu/">project page</a> / -->
              <a href="https://www.aclweb.org/anthology/2020.challengehml-1.9/">paper</a> /
              <a href="https://ivc.ischool.utexas.edu/~yz9244/VizWiz_workshop/videos/101-poster.mp4">talk</a>
              <p></p>
              <p>We present a consistency analysis of VQA models through the lens of attribution to evaluate adversarial robustness.</p>
            </td>
          </tr> 
          </tbody>
        </table>
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Affiliations</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
              <td>
                <center><a href="http://www.coep.org.in/" target="_blank">
                  <img src="data/coeplogo.png" width="100px" height="100px"></a></center>
              </td>
              <td>
                <center><a href="http://www.cmu.edu/" target="_blank">
                    <img src="data/cmu-logo.png"></a></center>
              </td>
              <td>
                <center><a href="http://viterbi.usc.edu/" target="_blank">
                  <img src="data/viterbi-logo.jpg"></a></center>
              </td>
          </tr><tr>
          </tr><tr>
              <td>College of Engineering Pune<br><br><center>2018-2022</center></td>
              <td>Carnegie Mellon University<br><br><center>Summer 2021 - Present</center></td>
              <td>University of Southern California<br> <a href="https://ai.facebook.com/">w/ Facebook AI Research</a><br><center>Summer 2021 - Present</center></td>
          </tr>
        </tbody></table>
        !-->
          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Blogs</heading>
              </td>
            </tr>
          </tbody></table>
            
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
         
            <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                
                <div class="one"> -->
                  <!-- <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/nlt_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div> -->
                  <!-- <img src='data/medium.jpeg' style = "width:100%; height:100%">
                </div>
                
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://medium.com/swlh/object-detection-and-instance-segmentation-a-detailed-overview-94ca109274f2?source=your_stories_page---------------------------">
                  <papertitle>Object Detection and Instance Segmentation:  A Detailed Overview</papertitle>
                </a>
                <p>
                  An illustrative guide to explain Region Proposal based Object Detection models.
                </p>
              </td>
            </tr> 
            <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                
                <div class="one">
                  <!-- <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/nlt_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div> -->
                  <!-- <img src='data/medium2.png' style = "width:100%; height:100%">
                </div>
                
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://medium.com/@shaunak.halbe/stability-of-network-community-under-adversarial-attack-aba1dbec6e73">
                  <papertitle>Stability of Network Community under Adversarial Attacks</papertitle>
                </a>
                <p>
                  A Study of Network Security and Concealment of Agent Identity.
                </p>
              </td>
            </tr>  -->

            <!-- <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                
                <div class="one"> -->
                  <!-- <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/nlt_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div> -->
                  <!-- <img src='data/9.png' style = "width:100%; height:100%">
                </div>
                
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="./data/yoloblog.pdf">
                  <papertitle>A Simple explanation to the YOLO Algorithm</papertitle>
                </a>
                <p>
                  A gentle introduction to the YOLO Algorithm for Real-Time Object Detection.
                </p>
              </td>
            </tr> 
            </tbody>
            </table>

             <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody> -->
             <!-- <tr>
                <td>
                  <heading>Projects</heading>
                </td>
              </tr>
            </tbody></table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
         
              <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  
                  <div class="one">
                    
                    <img src='data/bert.png' width="150" height ="150">
                  </div>
                  
                </td>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://github.com/shaunak27/">
                  <papertitle>Machine Reading Comprehension using Transformer based Models</papertitle>
                </a>
                <p>
                  <i>(Ongoing)</i> <br> <br>
                  Using Transformer based architectures like BERT, RoBERTa for the Question-Answering
                  task on SQuAD 2.0 dataset. 
                </p>
              </td>
            </tr> 
            <td style="padding:20px;width:25%;vertical-align:middle">
                  
              <div class="one">
                
                <img src='data/index.jpeg' width="150" height ="150">
              </div>
              
            </td>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/shaunak27/Multilingual-Image-Captioning">
              <papertitle>Multilingual Image Captioning </papertitle>
            </a>
            <p>
              The system consists of an Encoder-Decoder Image Captioning Model augmented with a NMT and Text-To-Speech
              pipeline to aid the Visually Impaired.
            </p>
          </td>
        </tr>  
        
        <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            
            <div class="one">
              
              <img src='data/10.jpg' width="150" height ="150">
            </div>
            
          </td>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/shaunak27/Object-Detection-and-Instance-Segmentation">
            <papertitle>Object Detection and Instance Segmentation using Mask RCNN</papertitle>
          </a>
          <p>
            Comparative Study of using various CNN Models as backbones for Mask-RCNN model for the 
            detection and segmentation of pedestrian images.
        
          </p>
        </td>
      </tr> 


      <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          
          <div class="one">
           
            <img src='data/adversarial.png' width="150" height ="150">
          </div>
          
        </td>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://github.com/shaunak27/Adversarial-Training-on-MNIST-Dataset">
          <papertitle>Adversarial Training on MNIST images</papertitle>
        </a>
        <p>
          Studying the effects of Adversarial Training as a defense against
          PGD, FGSM, and I-FGSM attacks using Pytorch on MNIST.
      
        </p>
      </td>
    </tr> 

  -->

            <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
              <tr>
                <td>
                  <heading>Presentations</heading>
                </td>
              </tr>
            </tbody></table>
            <table width="100%" align="center" border="0" cellpadding="20"><tbody>
              <td width="100%" valign="center">
                <a href="https://visualqa.org/">1. Poster Presentation, VQA Workshop CVPR 2020</a>
                <br>
         </td>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/nvvEGeVGKzM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
                  </iframe>
                </td>
             </tbody>
           </table>
           <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <td width="100%" valign="center">
              <a href="https://coepdsai.github.io/">2. Introduction to Computer Vision, DSAI Lecture Series</a>
              <br>
       </td>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/X6ZRTBuO20A" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
              </td>
              
         </tbody>
         </table>
         <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <td width="100%" valign="center">
            <a href="https://riss.ri.cmu.edu/">3. 2021 RISS Scholar Experience</a>
            <br>
     </td>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/JIXaMVj9qpo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </td>
            
       </tbody>
       </table>
 -->

 <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
  <tbody>
    <p>
      <heading id="awards"> Awards</heading>
    </p>
</td>
<td width="75%" valign="center">
  <ul>
<li><a href="https://riss.ri.cmu.edu/meet-the-2021-ri-summer-scholars/">CMU Robotics Institute Summer Scholarship (2021)</a></li>
<br>
<li><a href="https://viterbigrad.usc.edu/2021/07/iusstf-viterbi-program/">IUSSTF USC Viterbi Summer Research Fellowship (2021)</a> </li>
<br>
<li>COEP Gold Medal for Highest GPA in the graduating batch and in Computer Science (2022)</li>
<br>
<li>COEP Best Outgoing Student Award for achievements in academic and extracurricular activities (2022)</li>
</ul>
</td>
</tr>
</tbody>
</table>
 <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
  <tbody>
    <p>
      <heading id="service"> Service & Teaching</heading>
    </p>

</td>
<td width="75%" valign="center">
  <ul>
<li>Graduate Teaching Assistant: CS 7643
  Deep Learning</a>, Fall 2023</li>
<br>
<li>Reviewer: CVPR 2023, NeurIPS-W 2023, CMU RI Working Papers Journal 2021</li>
<br>
<li>Volunteer: NeurIPS 2023, CoRL 2023, NAACL 2021, ACL 2020 </li>
</td>
</tr>
</tbody>
</table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
             <br>
             <br>
             
              <p style="text-align: center;font-size: 14px;">Website template cloned from <a href = "https://jonbarron.info/" style="font-size: 14px;">here!</a>
              
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
